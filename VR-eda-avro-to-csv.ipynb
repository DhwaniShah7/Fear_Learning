{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5a73a0-7ec9-4f46-9243-60e95daedf2b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd8f934-c46a-4f12-89c4-614dc2d2da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import avro.schema\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a37a45-05c8-4f68-9601-230eb768701d",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac031f8f-c57b-4ae5-9f5f-1ebb4457b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ref = pd.read_excel('/Volumes/synapse/home/oredet01/VR/avros-to-analyze.xlsx')\n",
    "input_dir = '/Volumes/synapse/home/oredet01/VR/subject-avros/'\n",
    "output_dir = '/Volumes/synapse/home/oredet01/VR/subject-csvs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5fc72-14c3-456c-bd59-05c32f74d7f3",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7c79f8-1c99-4e53-88e9-3b69cff8485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eda_from_avro(file_path):\n",
    "    with open(file_path, 'rb') as avro_file:\n",
    "        reader = DataFileReader(avro_file, DatumReader())\n",
    "        record = next(reader)\n",
    "        rawData = record.get('rawData', None)\n",
    "        eda = rawData.get('eda', None)\n",
    "    return eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a932f6a4-3f45-4f38-99d3-4f7c7e4c4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_est_edt_to_utc(eastern_time):\n",
    "    eastern = pytz.timezone('America/New_York')\n",
    "    eastern_time = eastern.localize(eastern_time)\n",
    "    utc_time = eastern_time.astimezone(pytz.utc)\n",
    "    return utc_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f4e67-ecc2-455e-9b0e-3ed956b7e9ee",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79676693-fb85-4024-bbb3-c369dbd318ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in file_ref.iterrows():\n",
    "    input_path = (os.path.join(input_dir, row['SubID'], row['FileName-1']))\n",
    "    output_path = f\"{output_dir}{row['SubID']}/session-{row['Session']}\"\n",
    "    \n",
    "    start_time = convert_est_edt_to_utc(row['Start']).replace(tzinfo=None)\n",
    "    start_time = pd.to_datetime(start_time, unit='s', utc=True)\n",
    "    \n",
    "    end_time = convert_est_edt_to_utc(row['End']).replace(tzinfo=None)\n",
    "    end_time = pd.to_datetime(end_time, unit='s', utc=True)\n",
    "    \n",
    "    data = extract_eda_from_avro(input_path)\n",
    "    values = data['values']\n",
    "    timestamp_start = data['timestampStart']\n",
    "    sampling_frequency = data['samplingFrequency']\n",
    "    \n",
    "    # If eda data is split into 2 files, load in the values from file2\n",
    "    if isinstance(row['FileName-2'], str):\n",
    "        input_path2 = (os.path.join(input_dir, row['SubID'], row['FileName-2']))\n",
    "        data2 = extract_eda_from_avro(input_path2)\n",
    "        values2 = data2['values']\n",
    "        values.extend(values2)\n",
    "    \n",
    "    # Smooth eda values\n",
    "    values_smoothed = nk.signal_smooth(values, method = 'convolution', kernel = 'boxcar', size=3)\n",
    "    \n",
    "    # Convert timestamp_start from microseconds to seconds\n",
    "    timestamp_start_seconds = timestamp_start / 1_000_000\n",
    "    \n",
    "    # Generate a list of timestamps\n",
    "    time_seconds = list(range(len(values)))\n",
    "    timestamps = [timestamp_start_seconds + t / sampling_frequency for t in time_seconds]\n",
    "    \n",
    "    # Convert timestamps to datetime objects\n",
    "    datetime_objects = pd.to_datetime(timestamps, unit='s', utc=True)\n",
    "    \n",
    "    # Create a DataFrame with timestamps, raw, EDA values, and smoothed EDA values\n",
    "    df = pd.DataFrame({'timestamp': datetime_objects,\n",
    "                       'eda_raw': values, \n",
    "                       'eda_smoothed': values_smoothed})\n",
    "    \n",
    "    # Trim the DataFrame based on start and end time points of the experimental session\n",
    "    df = df[(df['timestamp'] >= start_time) & (df['timestamp'] <= end_time)].reset_index(drop=True)\n",
    "    \n",
    "    # Process the smoothed eda signal; add processed signals to DataFrame \n",
    "    signals, info = nk.eda_process(df['eda_smoothed'], sampling_rate=4)\n",
    "    df = pd.concat([df, signals], axis=1)\n",
    "    \n",
    "    # Save the DataFrame as a csv\n",
    "    df.to_csv(f\"{output_path}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5a73a0-7ec9-4f46-9243-60e95daedf2b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd8f934-c46a-4f12-89c4-614dc2d2da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import avro\n",
    "import avro.schema\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a37a45-05c8-4f68-9601-230eb768701d",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac031f8f-c57b-4ae5-9f5f-1ebb4457b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ref = pd.read_excel('/Users/dhwanishah/Desktop/MS/VR-Dhwani/avros-to-analyze.xlsx')\n",
    "input_dir = '/Users/dhwanishah/Desktop/MS/VR-Dhwani/subject-avros'\n",
    "output_dir = '/Users/dhwanishah/Desktop/MS/VR-Dhwani/subject-csvs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd5fc72-14c3-456c-bd59-05c32f74d7f3",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7c79f8-1c99-4e53-88e9-3b69cff8485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eda_from_avro(file_path):\n",
    "    with open(file_path, 'rb') as avro_file:\n",
    "        reader = DataFileReader(avro_file, DatumReader())\n",
    "        record = next(reader)\n",
    "        rawData = record.get('rawData', None)\n",
    "        eda = rawData.get('eda', None)\n",
    "    return eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a932f6a4-3f45-4f38-99d3-4f7c7e4c4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_est_edt_to_utc(eastern_time):\n",
    "    eastern = pytz.timezone('America/New_York')\n",
    "    eastern_time = eastern.localize(eastern_time)\n",
    "    utc_time = eastern_time.astimezone(pytz.utc)\n",
    "    return utc_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f4e67-ecc2-455e-9b0e-3ed956b7e9ee",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79676693-fb85-4024-bbb3-c369dbd318ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling frequency:4.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Users/dhwanishah/Desktop/MS/VR-Dhwani/subject-csvssub-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/9bsh4pdj35g8kpn493zfhbsr0000gn/T/ipykernel_18490/2036559916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Save the DataFrame as a csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output_path}.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/Users/dhwanishah/Desktop/MS/VR-Dhwani/subject-csvssub-1'"
     ]
    }
   ],
   "source": [
    "for index, row in file_ref.iterrows():\n",
    "    input_path = (os.path.join(input_dir, row['SubID'], row['FileName-1']))\n",
    "    output_path = f\"{output_dir}{row['SubID']}/session-{row['Session']}\"\n",
    "    \n",
    "    start_time = convert_est_edt_to_utc(row['Start']).replace(tzinfo=None)\n",
    "    start_time = pd.to_datetime(start_time, unit='s', utc=True)\n",
    "    \n",
    "    end_time = convert_est_edt_to_utc(row['End']).replace(tzinfo=None)\n",
    "    end_time = pd.to_datetime(end_time, unit='s', utc=True)\n",
    "    \n",
    "    data = extract_eda_from_avro(input_path)\n",
    "    values = data['values']\n",
    "    timestamp_start = data['timestampStart']\n",
    "    sampling_frequency = data['samplingFrequency']\n",
    "    print(f\"sampling frequency:{sampling_frequency}\")\n",
    "    \n",
    "    # If eda data is split into 2 files, load in the values from file2\n",
    "    if isinstance(row['FileName-2'], str):\n",
    "        input_path2 = (os.path.join(input_dir, row['SubID'], row['FileName-2']))\n",
    "        data2 = extract_eda_from_avro(input_path2)\n",
    "        values2 = data2['values']\n",
    "        values.extend(values2)\n",
    "    \n",
    "    # Smooth eda values\n",
    "    values_smoothed = nk.signal_smooth(values, method = 'convolution', kernel = 'boxcar', size=3)\n",
    "    \n",
    "    # Convert timestamp_start from microseconds to seconds\n",
    "    timestamp_start_seconds = timestamp_start / 1_000_000\n",
    "    \n",
    "    # Generate a list of timestamps\n",
    "    time_seconds = list(range(len(values)))\n",
    "    timestamps = [timestamp_start_seconds + t / sampling_frequency for t in time_seconds]\n",
    "    \n",
    "    # Convert timestamps to datetime objects\n",
    "    datetime_objects = pd.to_datetime(timestamps, unit='s', utc=True)\n",
    "    \n",
    "    # Create a DataFrame with timestamps, raw, EDA values, and smoothed EDA values\n",
    "    df = pd.DataFrame({'timestamp': datetime_objects,\n",
    "                       'eda_raw': values, \n",
    "                       'eda_smoothed': values_smoothed})\n",
    "    \n",
    "    # Trim the DataFrame based on start and end time points of the experimental session\n",
    "    df = df[(df['timestamp'] >= start_time) & (df['timestamp'] <= end_time)].reset_index(drop=True)\n",
    "    \n",
    "    # Process the smoothed eda signal; add processed signals to DataFrame \n",
    "    signals, info = nk.eda_process(df['eda_smoothed'], sampling_rate=4)\n",
    "    df = pd.concat([df, signals], axis=1)\n",
    "    \n",
    "    # Save the DataFrame as a csv\n",
    "    df.to_csv(f\"{output_path}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
